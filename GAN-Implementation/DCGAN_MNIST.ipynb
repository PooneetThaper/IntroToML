{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the MNIST data and storing it in ./MNIST_data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 32 # Number of images to run at each batch\n",
    "learning_rate = 0.0001 # Learning rate for optimizer\n",
    "logdir = './logs/dcgan_mnist/' # Logdir for tensorboard summaries\n",
    "num_adversarial_iter = 5000000 # Number of batches for the adversarial training\n",
    "num_discriminator_iter = 10000 # Number of batches to pretrain the discriminator\n",
    "pkeep = 0.75 # Probability with which to keep nodes during dropout\n",
    "print_all = False # Print all tensor names and shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions to create convolutional and fully connected layers with tensorboard summaries\n",
    "\n",
    "def conv_layer(input, kernel_size, channels_in, channels_out, stride, name, reuse_variables=None):\n",
    "    with tf.variable_scope(name, reuse=reuse_variables):\n",
    "        # Defining the graph of the operation\n",
    "        w = tf.get_variable('weights', [kernel_size, kernel_size, channels_in, channels_out],\n",
    "                            initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b = tf.get_variable('biases', [channels_out], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "        conv = tf.nn.conv2d(input, w, strides=[1, stride, stride, 1], padding=\"SAME\")\n",
    "        act = tf.nn.elu(conv + b, name='activation')\n",
    "\n",
    "        # Dropout regularization to prevent overfit\n",
    "        act_dropout = tf.nn.dropout(act, pkeep)\n",
    "\n",
    "        # Creating summaries for Tensorboard\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "\n",
    "        # Printing operation names and shapes for debugging\n",
    "        global print_all\n",
    "        if print_all:\n",
    "            print(w.name, w.shape)\n",
    "            print(b.name, b.shape)\n",
    "            print(conv.name, conv.shape)\n",
    "            print(act.name, act.shape)\n",
    "\n",
    "        return act_dropout\n",
    "\n",
    "def fc_layer(input, size_in, size_out, name, activation, reuse_variables=None):\n",
    "    with tf.variable_scope(name, reuse=reuse_variables):\n",
    "        # Defining the graph of the operation\n",
    "        w = tf.get_variable('weights', [size_in, size_out], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b = tf.get_variable('biases', [size_out], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "        logit = tf.matmul(input, w) + b\n",
    "\n",
    "        # Creating summaries for Tensorboard\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "\n",
    "        # Printing operation names and shapes for debugging\n",
    "        global print_all\n",
    "        if print_all:\n",
    "            print(w.name, w.shape)\n",
    "            print(b.name, b.shape)\n",
    "            print(logit.name, logit.shape)\n",
    "\n",
    "        # Covering the different cases needed\n",
    "        if activation == 'linear':\n",
    "            logit_dropout = tf.nn.dropout(logit, pkeep)\n",
    "            tf.summary.histogram(\"activations\", logit)\n",
    "            return logit_dropout\n",
    "        elif activation == 'elu':\n",
    "            act = tf.nn.elu(logit, name='activation')\n",
    "            act_dropout = tf.nn.dropout(act, pkeep)\n",
    "            tf.summary.histogram(\"activations\", act)\n",
    "            if print_all:\n",
    "                   print(act.name, act.shape)\n",
    "            return act_dropout\n",
    "\n",
    "def deconv_layer(input, kernel_size, channels_in, channels_out, stride, name, activation, reuse_variables=None):\n",
    "    input_shape = input.get_shape().as_list()\n",
    "    with tf.variable_scope(name, reuse=reuse_variables):\n",
    "        # Defining the graph of the operation\n",
    "        w = tf.get_variable('weights', [kernel_size, kernel_size, channels_out, channels_in],\n",
    "                            initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b = tf.get_variable('biases', [channels_out], initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "        conv = tf.nn.conv2d_transpose(input, w,\n",
    "                                      output_shape=[input_shape[0], input_shape[1]*stride, input_shape[2]*stride, channels_out],\n",
    "                                      strides=[1, stride, stride, 1], padding=\"SAME\")\n",
    "\n",
    "        # Creating summaries for Tensorboard\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "\n",
    "        # Printing operation names and shapes for debugging\n",
    "        global print_all\n",
    "        if print_all:\n",
    "            print(w.name, w.shape)\n",
    "            print(b.name, b.shape)\n",
    "            print(conv.name, conv.shape)\n",
    "\n",
    "        # Covering the different cases needed\n",
    "        if activation == 'elu':\n",
    "            act = tf.nn.elu(conv + b, name='activation')\n",
    "            act_dropout = tf.nn.dropout(act, pkeep)\n",
    "            if print_all:\n",
    "                print(act.name, act.shape)\n",
    "            tf.summary.histogram(\"activations\", act)\n",
    "            return act_dropout\n",
    "        elif activation == 'sigmoid':\n",
    "            act = tf.nn.sigmoid(conv + b, name='activation')\n",
    "            if print_all:\n",
    "                print(act.name, act.shape)\n",
    "            tf.summary.histogram(\"activations\", act)\n",
    "            return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the discriminator\n",
    "\n",
    "# input: [batch_size, 28, 28, 1]\n",
    "# output: [batch_size, 1]\n",
    "\n",
    "# 2 convolutional layers: input_shape = [-1, 28, 28, 1], output_shape = [-1, 7, 7, 64]\n",
    "# - Conv1: 32 5x5 filters, stride 2x2, padding = same, input_shape = [-1, 28, 28, 1]\n",
    "#   - weights: shape = [5, 5, 1, 32], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [32], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - strides: [1, 2, 2, 1]\n",
    "#   - activation: tf.nn.elu\n",
    "# - Conv2: 64 5x5 filters, stride 2x2, padding = same, input_shape = [-1, 14, 14, 64]\n",
    "#   - weights: shape = [5, 5, 32, 64], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [64], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - strides: [1, 2, 2, 1]\n",
    "#   - activation: tf.nn.elu\n",
    "# Reshape into vectors: input_shape = [-1, 7, 7, 64], output_shape = [-1, 7 * 7 * 64]\n",
    "# 3 fully connected layers: input_shape = [-1, 3136], output_shape = [-1, 1]\n",
    "# - FC1: input_shape = [-1, 3136]\n",
    "#   - weights: shape = [3136, 1024], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [1024], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - activation: tf.nn.elu\n",
    "# - FC2: input_shape = [-1, 1024]\n",
    "#   - weights: shape = [1024, 128], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [128], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - activation: tf.nn.elu\n",
    "# - FC3: input_shape = [-1, 128]\n",
    "#   - weights: shape = [128, 1], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [1], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - activation: linear\n",
    "\n",
    "# Loss: tf.sigmoid_cross_entropy_with_logits\n",
    "# Optimizer: tf.train.AdamOptimizer\n",
    "\n",
    "def discriminator(images, reuse_variables=None):\n",
    "    if not reuse_variables:\n",
    "        print('Initializing Discriminator')\n",
    "    else:\n",
    "        print('Reusing Discriminator')\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=reuse_variables):\n",
    "        d_conv_1 = conv_layer(input=images, kernel_size=5, channels_in=1, channels_out= 32, stride=2,\n",
    "                                    name='discriminator_conv_1', reuse_variables=reuse_variables)\n",
    "        d_conv_2 = conv_layer(input=d_conv_1, kernel_size=5, channels_in=32, channels_out= 64, stride=2,\n",
    "                                    name='discriminator_conv_2', reuse_variables=reuse_variables)\n",
    "        flattened = tf.reshape(d_conv_2, [-1, 7*7*64])\n",
    "        d_fc_1 = fc_layer(input=flattened, size_in=7*7*64, size_out=1024, activation='elu', name='discriminator_fc_1',\n",
    "                          reuse_variables=reuse_variables)\n",
    "        d_fc_2 = fc_layer(input=d_fc_1, size_in=1024, size_out=128, activation='elu', name='discriminator_fc_2',\n",
    "                          reuse_variables=reuse_variables)\n",
    "        d_fc_3 = fc_layer(input=d_fc_2, size_in=128, size_out=1, activation='linear', name='discriminator_fc_3',\n",
    "                          reuse_variables=reuse_variables)\n",
    "        return d_fc_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining the generator\n",
    "\n",
    "# input: [batch_size, 128]\n",
    "# output: [batch_size, 28, 28, 1]\n",
    "\n",
    "# 2 fully connected layers: input_shape = [-1, 128], output_shape = [-1, 7 * 7 * 64]\n",
    "# - FC1: input_shape = [-1, 128], output_shape = [-1, 1024]\n",
    "#   - weights: shape = [128, 1024], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [1024], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - activation: tf.nn.elu\n",
    "# - FC2: input_shape = [-1, 1024], output_shape = [-1, 7 * 7 * 128]\n",
    "#   - weights: shape = [1024, 7 * 7 * 64], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [7 * 7 * 64], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - activation: tf.nn.elu\n",
    "# Reshape data: input_shape = [-1,7*7*64] output_shape = [-1, 7, 7, 64]\n",
    "# 2 transpose convolution layers: input_shape = [-1, 7, 7, 64], output_shape = [-1, 28, 28, 1]\n",
    "# - Transpose_Conv1: input_shape = [-1, 7, 7, 64], output_shape = [-1, 14, 14, 32]\n",
    "#   - weights: shape = [5, 5, 64, 32], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [64], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - strides: [1, 2, 2, 1]\n",
    "#   - activation: tf.nn.elu\n",
    "# - Transpose_Conv2: input_shape = [-1, 14, 14, 32], output_shape = [-1, 28, 28, 1]\n",
    "#   - weights: shape = [5, 5, 32, 1], initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "#   - bias: shape = [1], initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#   - strides: [1, 2, 2, 1]\n",
    "#   - activation: tf.nn.sigmoid\n",
    "\n",
    "# Loss: tf.sigmoid_cross_entropy_with_logits\n",
    "# Optimizer: tf.train.AdamOptimizer\n",
    "\n",
    "def generator(z, reuse_variables=None):\n",
    "    if not reuse_variables:\n",
    "        print('Initializing Generator')\n",
    "    else:\n",
    "        print('Reusing Generator')\n",
    "    with tf.variable_scope(tf.get_variable_scope()):\n",
    "        g_fc_1 = fc_layer(input=z, size_in=128, size_out=1024, activation='elu', name='generator_fc_1', \n",
    "                          reuse_variables=reuse_variables)\n",
    "        g_fc_2 = fc_layer(input=g_fc_1, size_in=1024, size_out=7*7*64, activation='elu', name='generator_fc_2', \n",
    "                          reuse_variables=reuse_variables)\n",
    "        reshaped = tf.reshape(g_fc_2, [-1, 7, 7, 64])\n",
    "        g_deconv_1 = deconv_layer(input=reshaped, kernel_size=5, channels_in=64, channels_out= 32, stride=2,\n",
    "                                        name='generator_deconv_1', activation='elu', reuse_variables=reuse_variables)\n",
    "        g_deconv_2 = deconv_layer(input=g_deconv_1, kernel_size=5, channels_in=32, channels_out= 1, stride=2,\n",
    "                                        name='generator_deconv_2', activation='sigmoid', reuse_variables=reuse_variables)\n",
    "        return g_deconv_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing that the graphs work as intended\n",
    "# Using a constant zero vector of the correct shape to get the resulting tensors and their shapes\n",
    "\n",
    "#with print_all = True:\n",
    "#    const = tf.constant(0, shape=[28*28, 128], dtype=tf.float32)\n",
    "#    gen = generator(const)\n",
    "#    reshaped_const = tf.reshape(const, [-1, 28, 28, 1])\n",
    "#    discrim1 = discriminator(reshaped_const)\n",
    "#    discrim2 = discriminator(reshaped_const, True)\n",
    "\n",
    "\n",
    "# Print the nodes in the graph\n",
    "#[n.name for n in tf.get_default_graph().as_graph_def().node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the graphs, loss, optimizers, and summaries\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Creating placeholders for input to graph\n",
    "z_placeholder = tf.placeholder(tf.float32, [batch_size, 128], name = 'z_placeholder')\n",
    "images_placeholder = tf.placeholder(tf.float32, [batch_size, 784], name = 'images_placeholder')\n",
    "images_reshaped = tf.reshape(images_placeholder, [-1, 28, 28, 1])\n",
    "tf.summary.image('Input_images', images_reshaped, 6)\n",
    "\n",
    "# Initializing Generator and Discriminators\n",
    "Generator = generator(z_placeholder)\n",
    "Discriminator_real = discriminator(images_reshaped)\n",
    "Discriminator_fake = discriminator(Generator, reuse_variables=True)\n",
    "\n",
    "# Defining loss functions for networks\n",
    "with tf.name_scope('Cross_Entropy'):\n",
    "    D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Discriminator_real,\n",
    "                                                                         labels=tf.zeros_like(Discriminator_real)))\n",
    "    D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Discriminator_fake,\n",
    "                                                                         labels=tf.ones_like(Discriminator_fake)))\n",
    "    G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Discriminator_fake,\n",
    "                                                                    labels=tf.zeros_like(Discriminator_fake)))\n",
    "    tf.summary.scalar('D_loss_real', D_loss_real)\n",
    "    tf.summary.scalar('D_loss_fake', D_loss_fake)\n",
    "    tf.summary.scalar('G_loss', G_loss)\n",
    "\n",
    "# Getting the variables for each network to update only certain weights during each optimization\n",
    "tvars = tf.trainable_variables()\n",
    "D_vars = [var for var in tvars if 'discriminator_' in var.name]\n",
    "G_vars = [var for var in tvars if 'generator_' in var.name]\n",
    "\n",
    "# Defining the optimizer (Adam adaptive learning rate and momemtum optimizer)\n",
    "with tf.name_scope('Train'):\n",
    "    D_train_real = tf.train.AdamOptimizer(learning_rate).minimize(D_loss_real, var_list=D_vars)\n",
    "    D_train_fake = tf.train.AdamOptimizer(learning_rate).minimize(D_loss_fake, var_list=D_vars)\n",
    "    G_train = tf.train.AdamOptimizer(learning_rate).minimize(G_loss, var_list=G_vars)\n",
    "\n",
    "# Defining graph for generating a sample image\n",
    "z_sample = tf.placeholder(dtype = tf.float32, shape = [6, 128], name='z_sample')\n",
    "sample_images = generator(z_sample, True)\n",
    "tf.summary.image('Generated_images', sample_images, 6)\n",
    "\n",
    "# Write out images to disk\n",
    "output_image_placeholder = tf.placeholder(dtype = tf.float32, shape = [28, 28, 1], name='output_image_placeholder')\n",
    "cast_image = tf.cast(tf.multiply(output_image_placeholder, 255), tf.uint8)\n",
    "encode_image = tf.image.encode_jpeg(cast_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Tensorflow session and intialize variables\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Summary merging and writing\n",
    "saver = tf.train.Saver()\n",
    "summ = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(logdir + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\")\n",
    "writer.add_graph(sess.graph)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Generate a sample image before training\n",
    "image = sess.run(sample_images, feed_dict={z_sample: np.random.normal(-1,1,[6,128])})\n",
    "fig, ax = plt.subplots(1, 6, figsize = (15, 24))\n",
    "for i, a in enumerate(ax):\n",
    "    a.imshow(image[i].squeeze(), cmap='gray_r') # Squeeze the output of the generator down to two dimensions\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretraining for discriminator\n",
    "for i in range(num_discriminator_iter):\n",
    "    image_batch = mnist.train.next_batch(batch_size)\n",
    "    z_input = np.random.normal(-1, 1, [batch_size, 128])\n",
    "\n",
    "    sess.run([D_train_real, D_train_fake], feed_dict={images_placeholder: image_batch[0],\n",
    "                                                      z_placeholder: z_input})\n",
    "    if i % 100 == 0:\n",
    "        image_batch_val = mnist.train.next_batch(batch_size)\n",
    "        z_val = np.random.normal(-1, 1, [batch_size, 128])\n",
    "\n",
    "        real_loss, fake_loss = sess.run([D_loss_real, D_loss_fake], feed_dict={images_placeholder: image_batch_val[0],\n",
    "                                                                                z_placeholder: z_val})\n",
    "        print(i, real_loss, fake_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train networks together \n",
    "# (wouldnt suggest running this cell unless youre willing to wait at least 1.5 to 2 hours even on a GPU)\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "for i in range(num_adversarial_iter):\n",
    "    image_batch = mnist.train.next_batch(batch_size)\n",
    "    z_input = np.random.normal(-1, 1, [batch_size, 128])\n",
    "\n",
    "    sess.run([D_train_real, D_train_fake, G_train], feed_dict={images_placeholder: image_batch[0],\n",
    "                                                               z_placeholder: z_input})\n",
    "\n",
    "    if i%100 == 0:\n",
    "        z_val = np.random.normal(-1, 1, [batch_size, 128])\n",
    "        image_batch_val = mnist.train.next_batch(batch_size)\n",
    "        z_summary = np.random.normal(-1, 1, [6, 128])\n",
    "        s = sess.run(summ, {z_placeholder: z_val, images_placeholder: image_batch_val[0], z_sample: z_summary})\n",
    "        writer.add_summary(s, i)\n",
    "        if i%10000 == 0:\n",
    "            image = sess.run(sample_images, feed_dict={z_sample: z_summary})\n",
    "            plt.close()\n",
    "            fig, ax = plt.subplots(1, 6, figsize = (15, 24))\n",
    "            for j, a in enumerate(ax):\n",
    "                im = image[j].squeeze()\n",
    "                a.imshow(im, cmap='gray_r') # Squeeze the output of the generator down to two dimensions\n",
    "            plt.show(block=False)\n",
    "            if i%100000 == 0:\n",
    "                #if not os.path.exists('sample_images'):\n",
    "                #    os.makedirs('sample_images')\n",
    "                #for j in range(image.shape[0]):\n",
    "                #    image_jpeg = sess.run(encode_image, feed_dict={output_image_placeholder: image[j] })\n",
    "                #    with open('sample_images/iter_{}_sample_{}.jpeg'.format(i,j), 'wb') as fd:\n",
    "                #        fd.write(image_jpeg)\n",
    "                if not os.path.exists('sample_generated'):\n",
    "                    os.makedirs('sample_generated')\n",
    "                for j in range(image.shape[0]):\n",
    "                    np.savetxt('sample_generated/iter_{}_sample_{}.csv'.format(i,j), image[j], delimiter=',')\n",
    "    if i%1000 == 0:\n",
    "        z_test = np.random.normal(-1, 1, [batch_size, 128])\n",
    "        image_batch_test = mnist.train.next_batch(batch_size)\n",
    "        d_loss_real, d_loss_fake, g_loss = sess.run([D_loss_real, D_loss_fake, G_loss],\n",
    "                                                    feed_dict={images_placeholder: image_batch_test[0],\n",
    "                                                               z_placeholder: z_test})\n",
    "        print(i, d_loss_real, d_loss_fake, g_loss)\n",
    "    if i%100000 == 0:\n",
    "        if not os.path.exists('saved_models'):\n",
    "            os.makedirs('saved_models')\n",
    "        print('Saving model at iteration {}'.format(i))\n",
    "        save_path = saver.save(sess, 'saved_models/model'.format(i), global_step=i)\n",
    "        print('Model saved at {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses (run on desktop and saved as txt files to show)\n",
    "import pandas as pd\n",
    "\n",
    "pretraining_loss = pd.read_csv('losses/discriminator_pretraining.txt', delim_whitespace=True).as_matrix()\n",
    "training_loss = pd.read_csv('losses/adversarial_training.txt', delim_whitespace=True).as_matrix()\n",
    "\n",
    "plt.close()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14,12))\n",
    "\n",
    "ax1.plot(pretraining_loss[:,0], pretraining_loss[:,1], label='Loss on real images')\n",
    "ax1.plot(pretraining_loss[:,0], pretraining_loss[:,2], label='Loss on generated images')\n",
    "ax1.legend()\n",
    "ax1.set_title('Pretraining loss for discriminator')\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Cross Entropy')\n",
    "\n",
    "ax2.plot(training_loss[:,0], training_loss[:,1], label='Discriminator loss on real images')\n",
    "ax2.plot(training_loss[:,0], training_loss[:,2], label='Discriminator loss on generated images')\n",
    "ax2.plot(training_loss[:,0], training_loss[:,3], label='Generator loss on generated images')\n",
    "ax2.legend()\n",
    "ax2.set_title('Training loss for discriminator and generator')\n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_xticks(np.arange(0, max(training_loss[:,0])+1, 250000))\n",
    "ax2.set_ylabel('Cross Entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "## https://github.com/jonbruner/generative-adversarial-networks\n",
    "## https://github.com/soumith/ganhacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
